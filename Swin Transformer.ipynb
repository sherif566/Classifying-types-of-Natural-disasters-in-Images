{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8393463,"sourceType":"datasetVersion","datasetId":4993079},{"sourceId":8418243,"sourceType":"datasetVersion","datasetId":5011213}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-05-29T12:49:26.577559Z","iopub.execute_input":"2024-05-29T12:49:26.577935Z","iopub.status.idle":"2024-05-29T12:49:38.542271Z","shell.execute_reply.started":"2024-05-29T12:49:26.577878Z","shell.execute_reply":"2024-05-29T12:49:38.541306Z"},"jupyter":{"outputs_hidden":true}}},{"cell_type":"code","source":"pip install torch torchvision transformers pandas","metadata":{"execution":{"iopub.status.busy":"2024-05-29T12:49:38.544158Z","iopub.execute_input":"2024-05-29T12:49:38.544872Z","iopub.status.idle":"2024-05-29T12:49:51.666139Z","shell.execute_reply.started":"2024-05-29T12:49:38.544836Z","shell.execute_reply":"2024-05-29T12:49:51.665032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom PIL import Image  # Ensure correct import of PIL.Image\nimport torchvision \nimport torch\nimport numpy as np\nimport pandas as pd\nfrom torch.utils.data import Dataset, DataLoader, Subset\nimport torchvision.transforms as transforms\nfrom sklearn.model_selection import train_test_split\nfrom IPython.display import display, Image\nfrom transformers import SwinConfig, SwinForImageClassification\nfrom PIL import ImageFile\nimport torch.optim as optim\nfrom torch.nn import CrossEntropyLoss\nimport matplotlib.pyplot as plt\nfrom torch.optim.lr_scheduler import StepLR\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2024-05-29T12:49:51.667792Z","iopub.execute_input":"2024-05-29T12:49:51.668088Z","iopub.status.idle":"2024-05-29T12:49:59.155147Z","shell.execute_reply.started":"2024-05-29T12:49:51.668062Z","shell.execute_reply":"2024-05-29T12:49:59.154269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize an empty list to store the data\ndata = []\n\n# Set the base directory where the images are stored\nbase_dir = '/kaggle/input/comprehensive-disaster-datasetcdd/Comprehensive Disaster Dataset(CDD)'\n\n# Walk through the directory structure\nfor dirname, _, filenames in os.walk(base_dir):\n    for filename in filenames:\n        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n            label = os.path.basename(dirname)\n#             full_path = os.path.join(dirname, filename)\n            data.append({'filename': filename, 'label': label})\n\n# Create a DataFrame from the list\ndf = pd.DataFrame(data)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T12:49:59.157278Z","iopub.execute_input":"2024-05-29T12:49:59.157745Z","iopub.status.idle":"2024-05-29T12:50:01.375201Z","shell.execute_reply.started":"2024-05-29T12:49:59.157718Z","shell.execute_reply":"2024-05-29T12:50:01.374411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-29T12:50:01.376321Z","iopub.execute_input":"2024-05-29T12:50:01.376623Z","iopub.status.idle":"2024-05-29T12:50:01.395448Z","shell.execute_reply.started":"2024-05-29T12:50:01.376598Z","shell.execute_reply":"2024-05-29T12:50:01.394535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2024-05-29T12:50:01.396469Z","iopub.execute_input":"2024-05-29T12:50:01.396858Z","iopub.status.idle":"2024-05-29T12:50:01.424192Z","shell.execute_reply.started":"2024-05-29T12:50:01.396831Z","shell.execute_reply":"2024-05-29T12:50:01.423266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Base directory where the images are stored\nbase_dir = '/kaggle/input/comprehensive-disaster-datasetcdd/Comprehensive Disaster Dataset(CDD)'\n\n# Prepare a list to collect data\ndata = []\n\n# Walk through the directory structure\nfor dirname, _, filenames in os.walk(base_dir):\n    for filename in filenames:\n        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):  # Check for image files\n            category = os.path.basename(dirname)  # The category is the name of the folder\n            data.append({'Image ID': filename, 'Category': category})\n\n# Create a DataFrame\ndf = pd.DataFrame(data)\n\n# Display the first few rows to verify\ndf.head()\n# Save the DataFrame to CSV if needed\ndf.to_csv('/kaggle/working/image_paths.csv', index=False)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-29T12:50:01.425312Z","iopub.execute_input":"2024-05-29T12:50:01.425607Z","iopub.status.idle":"2024-05-29T12:50:01.552743Z","shell.execute_reply.started":"2024-05-29T12:50:01.425582Z","shell.execute_reply":"2024-05-29T12:50:01.551849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-29T12:50:01.553864Z","iopub.execute_input":"2024-05-29T12:50:01.554132Z","iopub.status.idle":"2024-05-29T12:50:01.560142Z","shell.execute_reply.started":"2024-05-29T12:50:01.554109Z","shell.execute_reply":"2024-05-29T12:50:01.559225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-29T12:50:01.561268Z","iopub.execute_input":"2024-05-29T12:50:01.561564Z","iopub.status.idle":"2024-05-29T12:50:01.574334Z","shell.execute_reply.started":"2024-05-29T12:50:01.561541Z","shell.execute_reply":"2024-05-29T12:50:01.573420Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import multiprocessing\n\nmultiprocessing.set_start_method('fork', force=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-29T12:50:01.577872Z","iopub.execute_input":"2024-05-29T12:50:01.578165Z","iopub.status.idle":"2024-05-29T12:50:01.583640Z","shell.execute_reply.started":"2024-05-29T12:50:01.578134Z","shell.execute_reply":"2024-05-29T12:50:01.582537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DisasterDataset(Dataset):\n    def __init__(self, dataframe, root_dir, transform=None):\n        self.dataframe = dataframe\n        self.root_dir = root_dir\n        self.transform = transform\n        \n        # Create a mapping from string labels to integers\n        self.label_mapping = {label: idx for idx, label in enumerate(dataframe['Category'].unique())}\n        self.dataframe['label'] = dataframe['Category'].map(self.label_mapping)\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        img_name = os.path.join(self.root_dir, self.dataframe.iloc[idx, 0])\n        image = Image.open(img_name).convert('RGB')\n        label = self.dataframe.iloc[idx, 2]  # Changed to use the mapped integer label\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        # Convert label to tensor\n        label = torch.tensor(label).long()\n        \n        return image, label\n# Assuming df is your DataFrame\nroot_dir = '/kaggle/input/combind-dataset/Images Data'  # Update this to the directory containing your images","metadata":{"execution":{"iopub.status.busy":"2024-05-29T12:50:01.584745Z","iopub.execute_input":"2024-05-29T12:50:01.585070Z","iopub.status.idle":"2024-05-29T12:50:01.594212Z","shell.execute_reply.started":"2024-05-29T12:50:01.585041Z","shell.execute_reply":"2024-05-29T12:50:01.593218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.RandomRotation(10),\n    transforms.Resize((224, 224)),  \n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n])\n","metadata":{"execution":{"iopub.status.busy":"2024-05-29T12:50:01.595321Z","iopub.execute_input":"2024-05-29T12:50:01.595616Z","iopub.status.idle":"2024-05-29T12:50:01.606924Z","shell.execute_reply.started":"2024-05-29T12:50:01.595593Z","shell.execute_reply":"2024-05-29T12:50:01.606117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the dataset\nfull_dataset = DisasterDataset(df, root_dir, transform=transform)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T12:50:01.607894Z","iopub.execute_input":"2024-05-29T12:50:01.608147Z","iopub.status.idle":"2024-05-29T12:50:01.621213Z","shell.execute_reply.started":"2024-05-29T12:50:01.608125Z","shell.execute_reply":"2024-05-29T12:50:01.620519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the dataset into train, validation, and test sets\ntrain_indices, temp_indices = train_test_split(list(range(len(full_dataset))), test_size=0.2, random_state=42)\nval_indices, test_indices = train_test_split(temp_indices, test_size=0.5, random_state=42)\n\n# Create Subsets\ntrain_subset = Subset(full_dataset, train_indices)\nval_subset = Subset(full_dataset, val_indices)\ntest_subset = Subset(full_dataset, test_indices)\n\n# Create DataLoaders\nbatch_size = 32\ntrain_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, num_workers=4)\ntest_loader = DataLoader(test_subset, batch_size=batch_size, shuffle=False, num_workers=4)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T12:50:01.622293Z","iopub.execute_input":"2024-05-29T12:50:01.622603Z","iopub.status.idle":"2024-05-29T12:50:01.636418Z","shell.execute_reply.started":"2024-05-29T12:50:01.622579Z","shell.execute_reply":"2024-05-29T12:50:01.635653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Modify the SwinConfig for a smaller model\nconfig = SwinConfig.from_pretrained(\n    'microsoft/swin-tiny-patch4-window7-224',\n    num_labels=len(full_dataset.label_mapping),\n    hidden_dropout_prob=0.6,\n    attention_probs_dropout_prob=0.6\n)\n\n# Adjust the number of layers (depths) in each stage\n# Original depths for Swin-Tiny: [2, 2, 6, 2]\nconfig.depths = [2, 2, 5, 2]  # Reduce the number of transformer layers\n\n# Instantiate the model with the modified configuration\nmodel = SwinForImageClassification(config)\n\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-29T12:50:01.637559Z","iopub.execute_input":"2024-05-29T12:50:01.637865Z","iopub.status.idle":"2024-05-29T12:50:02.680357Z","shell.execute_reply.started":"2024-05-29T12:50:01.637842Z","shell.execute_reply":"2024-05-29T12:50:02.679309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ImageFile.LOAD_TRUNCATED_IMAGES = True","metadata":{"execution":{"iopub.status.busy":"2024-05-29T12:50:02.681585Z","iopub.execute_input":"2024-05-29T12:50:02.681979Z","iopub.status.idle":"2024-05-29T12:50:02.687023Z","shell.execute_reply.started":"2024-05-29T12:50:02.681947Z","shell.execute_reply":"2024-05-29T12:50:02.686050Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom PIL import Image  # Ensure correct import of PIL.Image\nimport torch\nfrom torch.utils.data import Dataset, DataLoader, Subset\nimport torchvision.transforms as transforms\nimport torchvision\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\n\n\ndef imshow(img, title=None):\n    img = img.numpy().transpose((1, 2, 0))  # convert from Tensor image\n    mean = np.array([0.5, 0.5, 0.5])  # example mean for normalization used\n    std = np.array([0.5, 0.5, 0.5])  # example std for normalization used\n    img = std * img + mean  # denormalize\n    img = np.clip(img, 0, 1)  # clip the image values to be between 0 and 1\n    plt.imshow(img)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)  # pause a bit so that plots are updated\n\n# Print some debug information\nprint(f\"Total dataset size: {len(full_dataset)}\")\nprint(f\"Training set size: {len(train_subset)}\")\nprint(f\"Validation set size: {len(val_subset)}\")\nprint(f\"Test set size: {len(test_subset)}\")\n\n# Verify DataLoader functionality\ntry:\n    dataiter = iter(train_loader)\n    images, labels = next(dataiter)\n    print(\"Batch loaded successfully.\")\n    \n    # Show images\n    imshow(torchvision.utils.make_grid(images), title='Some Training Images')\nexcept KeyError as e:\n    print(f\"KeyError encountered: {e}\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-29T12:50:02.688640Z","iopub.execute_input":"2024-05-29T12:50:02.688974Z","iopub.status.idle":"2024-05-29T12:50:04.653389Z","shell.execute_reply.started":"2024-05-29T12:50:02.688944Z","shell.execute_reply":"2024-05-29T12:50:04.652468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to visualize images\ndef imshow(img, title=None):\n    img = img / 2 + 0.5  # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    if title is not None:\n        plt.title(title)\n    plt.show()\n\n# Optimizer and loss function\noptimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\ncriterion = CrossEntropyLoss()\n\n# Scheduler\nscheduler = StepLR(optimizer, step_size=3, gamma=0.1)  # Decay LR by a factor of 0.1 every 3 epochs\n\n# Early Stopping Class (as defined above)\nclass EarlyStopping:\n    def __init__(self, patience=5, min_delta=0):\n        self.patience = patience\n        self.min_delta = min_delta\n        self.best_loss = float('inf')\n        self.counter = 0\n\n    def __call__(self, val_loss):\n        if val_loss < self.best_loss - self.min_delta:\n            self.best_loss = val_loss\n            self.counter = 0\n        else:\n            self.counter += 1\n        return self.counter >= self.patience\n\n# Initialize early stopping\nearly_stopping = EarlyStopping(patience=5, min_delta=0.01)\n\n# Lists to keep track of losses\ntrain_losses, val_losses = [], []\nnum_epochs = 100  # Set a high number of epochs and rely on early stopping\n\nfor epoch in range(num_epochs):\n    model.train()\n    total_loss, total_val_loss = 0, 0\n    \n    for i, (images, labels) in enumerate(train_loader):\n        images, labels = images.to(device), labels.to(device)\n        \n        # Visualize the first batch of each epoch\n        if i == 0:\n            plt.figure(figsize=(10, 10))\n            imshow(torchvision.utils.make_grid(images.cpu()), title=f'Epoch {epoch+1} - First batch')\n            plt.show()\n        \n        optimizer.zero_grad()\n        outputs = model(images)\n        logits = outputs.logits  # Extract the logits from the output\n        loss = criterion(logits, labels)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n    \n    train_losses.append(total_loss / len(train_loader))\n    \n    model.eval()\n    with torch.no_grad():\n        for images, labels in val_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            logits = outputs.logits  # Extract the logits from the output\n            val_loss = criterion(logits, labels)\n            total_val_loss += val_loss.item()\n    \n    val_losses.append(total_val_loss / len(val_loader))\n    print(f'Epoch {epoch+1}, Train Loss: {train_losses[-1]}, Val Loss: {val_losses[-1]}')\n\n    scheduler.step()  # Adjust the learning rate based on the scheduler\n    \n    # Check early stopping\n    if early_stopping(total_val_loss / len(val_loader)):\n        print(\"Early stopping triggered\")\n        break\n\n# Plot learning curves\nplt.figure(figsize=(10, 5))\nplt.plot(train_losses, label='Training Loss')\nplt.plot(val_losses, label='Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-29T12:50:04.655191Z","iopub.execute_input":"2024-05-29T12:50:04.655462Z","iopub.status.idle":"2024-05-29T13:11:21.039507Z","shell.execute_reply.started":"2024-05-29T12:50:04.655435Z","shell.execute_reply":"2024-05-29T13:11:21.038449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_mapping = full_dataset.label_mapping\nindex_to_class = {v: k for k, v in label_mapping.items()} # Reverse the mapping","metadata":{"execution":{"iopub.status.busy":"2024-05-29T13:11:21.041152Z","iopub.execute_input":"2024-05-29T13:11:21.041623Z","iopub.status.idle":"2024-05-29T13:11:21.046846Z","shell.execute_reply.started":"2024-05-29T13:11:21.041588Z","shell.execute_reply":"2024-05-29T13:11:21.045863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def denormalize(tensor, mean, std):\n    for t, m, s in zip(tensor, mean, std):\n        t.mul_(s).add_(m)\n    return tensor\n","metadata":{"execution":{"iopub.status.busy":"2024-05-29T13:11:21.047985Z","iopub.execute_input":"2024-05-29T13:11:21.048251Z","iopub.status.idle":"2024-05-29T13:11:21.058307Z","shell.execute_reply.started":"2024-05-29T13:11:21.048229Z","shell.execute_reply":"2024-05-29T13:11:21.057457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the test loop to calculate test accuracy\ndef test_model(model, test_loader, criterion, device):\n    model.eval()\n    total_test_loss = 0\n    correct_predictions = 0\n    total_predictions = 0\n\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            logits = outputs.logits  # Extract the logits from the output\n            loss = criterion(logits, labels)\n            total_test_loss += loss.item()\n\n            # Get the predicted class with the highest score\n            _, predicted = torch.max(logits, 1)\n            correct_predictions += (predicted == labels).sum().item()\n            total_predictions += labels.size(0)\n\n    average_test_loss = total_test_loss / len(test_loader)\n    test_accuracy = correct_predictions / total_predictions\n\n    print(f'Test Loss: {average_test_loss:.4f}, Test Accuracy: {test_accuracy * 100:.2f}%')\n    return average_test_loss, test_accuracy\n\n# Calculate test loss and accuracy\ntest_loss, test_accuracy = test_model(model, test_loader, criterion, device)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-29T13:11:21.059396Z","iopub.execute_input":"2024-05-29T13:11:21.059661Z","iopub.status.idle":"2024-05-29T13:11:27.025979Z","shell.execute_reply.started":"2024-05-29T13:11:21.059639Z","shell.execute_reply":"2024-05-29T13:11:27.024847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torchvision\n\ndef imshow(img, title=None):\n    mean = np.array([0.5, 0.5, 0.5])\n    std = np.array([0.5, 0.5, 0.5])\n    img = denormalize(img, mean, std)  # Denormalize the image\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))  # Convert from Tensor image and transpose to match image format\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)  # Pause a bit so that plots are updated\n\n# Modify the visualize_test_results function to display class names\ndef visualize_test_results(model, test_loader, device, num_images=20):\n    model.eval()\n    images_shown = 0\n\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            logits = outputs.logits\n            _, predicted = torch.max(logits, 1)\n\n            # Move images and predictions to CPU for visualization\n            images = images.cpu()\n            predicted = predicted.cpu()\n            labels = labels.cpu()\n\n            for i in range(images.size(0)):\n                if images_shown >= num_images:\n                    break\n                plt.figure(figsize=(6, 6))\n                imshow(torchvision.utils.make_grid(images[i]),\n                       title=f'True: {index_to_class[labels[i].item()]}, Pred: {index_to_class[predicted[i].item()]}')\n                images_shown += 1\n\n            if images_shown >= num_images:\n                break\n\n# Assuming you have already created the test_loader\nvisualize_test_results(model, test_loader, device)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-29T13:11:27.027751Z","iopub.execute_input":"2024-05-29T13:11:27.028611Z","iopub.status.idle":"2024-05-29T13:11:37.631460Z","shell.execute_reply.started":"2024-05-29T13:11:27.028571Z","shell.execute_reply":"2024-05-29T13:11:37.630437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}